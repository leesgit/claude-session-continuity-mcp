#!/usr/bin/env python3
"""
Session Start Hook v5 - ì‹œë§¨í‹± ê²€ìƒ‰ + ë‹¤ë‹¨ê³„ ë©”ëª¨ë¦¬ ê²€ìƒ‰

mcp-memory-service ìŠ¤íƒ€ì¼ êµ¬í˜„ + ì‹œë§¨í‹± ê²€ìƒ‰ ì¶”ê°€:
1. Phase 0: ì‹œë§¨í‹± ê²€ìƒ‰ (Git í‚¤ì›Œë“œ ê¸°ë°˜ ì„ë² ë”© ìœ ì‚¬ë„)
2. Phase 1: ìµœê·¼ ë©”ëª¨ë¦¬ (7ì¼ ì´ë‚´)
3. Phase 2: ì¤‘ìš” íƒœê·¸ (decision, error, architecture)
4. Phase 3: í´ë°± (ì¼ë°˜ í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸)

ëª©í‘œ: Zero re-explanation - ì„¸ì…˜ ì‹œì‘ ì‹œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ìë™ ì£¼ì…
ì‹œë§¨í‹± ê²€ìƒ‰: MCP ì„œë²„ì—ì„œ ìƒì„±í•œ ì„ë² ë”©(embeddings_v4)ì„ í™œìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
"""
from __future__ import annotations

import json
import sys
import os
import sqlite3
import subprocess
import re
import struct
import math
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple

WORKSPACE_ROOT = os.environ.get('WORKSPACE_ROOT', '/Users/ibyeongchang/Documents/dev/ai-service-generator')
DB_PATH = os.path.join(WORKSPACE_ROOT, '.claude', 'sessions.db')
APPS_DIR = os.path.join(WORKSPACE_ROOT, 'apps')

# ë©”ëª¨ë¦¬ ìŠ¬ë¡¯ ë°°ë¶„ (ì´ 12ê°œ - ì‹œë§¨í‹± ê²€ìƒ‰ ì¶”ê°€)
SLOT_CONFIG = {
    'semantic': 3,         # ì‹œë§¨í‹± ê²€ìƒ‰ (ì„ë² ë”© ìœ ì‚¬ë„)
    'git_related': 2,      # Git ì»¤ë°‹ ê´€ë ¨ (FTS)
    'recent': 3,           # ìµœê·¼ 7ì¼
    'important': 2,        # ì¤‘ìš” íƒœê·¸
    'fallback': 2          # ì¼ë°˜ ì»¨í…ìŠ¤íŠ¸
}

# ì¤‘ìš” íƒœê·¸
IMPORTANT_TAGS = ['decision', 'error', 'architecture', 'critical', 'important']

# ì„ë² ë”© ì°¨ì› (all-MiniLM-L6-v2)
EMBEDDING_DIM = 384


def bytes_to_float_array(data: bytes) -> List[float]:
    """ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ float ë°°ì—´ë¡œ ë³€í™˜"""
    if not data:
        return []
    # Float32Array í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨
    count = len(data) // 4
    return list(struct.unpack(f'{count}f', data))


def cosine_similarity(a: List[float], b: List[float]) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    if len(a) != len(b) or len(a) == 0:
        return 0.0

    dot = sum(x * y for x, y in zip(a, b))
    norm_a = math.sqrt(sum(x * x for x in a))
    norm_b = math.sqrt(sum(x * x for x in b))

    if norm_a == 0 or norm_b == 0:
        return 0.0

    return dot / (norm_a * norm_b)


def get_average_embedding(conn: sqlite3.Connection, memory_ids: List[int]) -> Optional[List[float]]:
    """ì—¬ëŸ¬ ë©”ëª¨ë¦¬ì˜ í‰ê·  ì„ë² ë”© ê³„ì‚°"""
    cursor = conn.cursor()
    embeddings = []

    for mid in memory_ids[:10]:  # ìµœëŒ€ 10ê°œë§Œ
        cursor.execute('''
            SELECT embedding FROM embeddings_v4
            WHERE entity_type = 'memory' AND entity_id = ?
        ''', (mid,))
        row = cursor.fetchone()
        if row and row[0]:
            emb = bytes_to_float_array(row[0])
            if len(emb) == EMBEDDING_DIM:
                embeddings.append(emb)

    if not embeddings:
        return None

    # í‰ê·  ê³„ì‚°
    avg = [0.0] * EMBEDDING_DIM
    for emb in embeddings:
        for i in range(EMBEDDING_DIM):
            avg[i] += emb[i]

    for i in range(EMBEDDING_DIM):
        avg[i] /= len(embeddings)

    return avg


def search_semantic_memories(conn: sqlite3.Connection, project: str, keywords: List[str], limit: int) -> List[Dict]:
    """ì‹œë§¨í‹± ê²€ìƒ‰: í‚¤ì›Œë“œ ê´€ë ¨ ë©”ëª¨ë¦¬ì˜ ì„ë² ë”©ìœ¼ë¡œ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ ê²€ìƒ‰"""
    cursor = conn.cursor()

    # 1. í‚¤ì›Œë“œë¡œ ì‹œë“œ ë©”ëª¨ë¦¬ ì°¾ê¸° (FTS)
    seed_ids = []
    if keywords:
        try:
            fts_query = ' OR '.join(keywords[:5])
            cursor.execute('''
                SELECT m.id FROM memories m
                JOIN memories_fts fts ON m.id = fts.rowid
                WHERE memories_fts MATCH ? AND m.project = ?
                LIMIT 5
            ''', (fts_query, project))
            seed_ids = [row[0] for row in cursor.fetchall()]
        except:
            pass

    # ì‹œë“œê°€ ì—†ìœ¼ë©´ ìµœê·¼ ì¤‘ìš” ë©”ëª¨ë¦¬ ì‚¬ìš©
    if not seed_ids:
        cursor.execute('''
            SELECT id FROM memories
            WHERE project = ? AND (memory_type IN ('decision', 'error') OR importance >= 7)
            ORDER BY created_at DESC LIMIT 5
        ''', (project,))
        seed_ids = [row[0] for row in cursor.fetchall()]

    if not seed_ids:
        return []

    # 2. ì‹œë“œ ë©”ëª¨ë¦¬ë“¤ì˜ í‰ê·  ì„ë² ë”© ê³„ì‚°
    query_embedding = get_average_embedding(conn, seed_ids)
    if not query_embedding:
        return []

    # 3. ëª¨ë“  í”„ë¡œì íŠ¸ ë©”ëª¨ë¦¬ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    cursor.execute('''
        SELECT m.id, m.content, m.memory_type, m.importance, m.created_at, m.tags, e.embedding
        FROM memories m
        JOIN embeddings_v4 e ON e.entity_type = 'memory' AND e.entity_id = m.id
        WHERE m.project = ? AND m.id NOT IN ({})
    '''.format(','.join('?' * len(seed_ids))), (project, *seed_ids))

    results = []
    for row in cursor.fetchall():
        if not row[6]:
            continue
        emb = bytes_to_float_array(row[6])
        if len(emb) != EMBEDDING_DIM:
            continue

        similarity = cosine_similarity(query_embedding, emb)
        results.append({
            'id': row[0],
            'content': row[1],
            'type': row[2],
            'importance': row[3],
            'created_at': row[4],
            'tags': row[5],
            'source': 'semantic',
            'similarity': similarity
        })

    # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
    results.sort(key=lambda x: x['similarity'], reverse=True)
    return results[:limit]


def get_project_from_cwd(cwd: str) -> Optional[str]:
    """cwdì—ì„œ í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ"""
    if "/apps/" in cwd:
        parts = cwd.split("/apps/")
        if len(parts) > 1:
            return parts[1].split("/")[0]
    if "/tools/" in cwd:
        parts = cwd.split("/tools/")
        if len(parts) > 1:
            return parts[1].split("/")[0]
    return None


def run_git_command(args: List[str], cwd: str) -> Optional[str]:
    """Git ëª…ë ¹ ì‹¤í–‰"""
    try:
        result = subprocess.run(
            ['git'] + args,
            cwd=cwd,
            capture_output=True,
            text=True,
            timeout=5
        )
        return result.stdout.strip() if result.returncode == 0 else None
    except:
        return None


def extract_git_keywords(project_path: str) -> List[str]:
    """ìµœê·¼ ì»¤ë°‹ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keywords = set()

    # ìµœê·¼ 5ê°œ ì»¤ë°‹ ë©”ì‹œì§€
    output = run_git_command(['log', '-5', '--pretty=%s'], project_path)
    if output:
        for line in output.split('\n'):
            # ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ ì¶”ì¶œ (3ê¸€ì ì´ìƒ)
            words = re.findall(r'[ê°€-í£]{2,}|[a-zA-Z]{3,}', line)
            keywords.update(w.lower() for w in words)

    # ìµœê·¼ ë³€ê²½ íŒŒì¼ ê¸°ë°˜ í‚¤ì›Œë“œ
    output = run_git_command(['diff', '--name-only', 'HEAD~3..HEAD'], project_path)
    if output:
        for f in output.split('\n'):
            if f:
                # íŒŒì¼ ê²½ë¡œì—ì„œ í‚¤ì›Œë“œ
                parts = f.replace('/', ' ').replace('_', ' ').replace('-', ' ').split()
                keywords.update(p.lower() for p in parts if len(p) >= 3)

    return list(keywords)[:20]  # ìµœëŒ€ 20ê°œ


def search_memories_by_keywords(conn: sqlite3.Connection, project: str, keywords: List[str], limit: int) -> List[Dict]:
    """í‚¤ì›Œë“œë¡œ ë©”ëª¨ë¦¬ ê²€ìƒ‰ (FTS)"""
    if not keywords:
        return []

    cursor = conn.cursor()
    results = []
    seen_ids = set()

    # FTS ê²€ìƒ‰
    try:
        fts_query = ' OR '.join(keywords[:10])
        cursor.execute('''
            SELECT m.id, m.content, m.memory_type, m.importance, m.created_at, m.tags
            FROM memories m
            JOIN memories_fts fts ON m.id = fts.rowid
            WHERE memories_fts MATCH ? AND m.project = ?
            ORDER BY m.importance DESC, m.created_at DESC
            LIMIT ?
        ''', (fts_query, project, limit * 2))

        for row in cursor.fetchall():
            if row[0] not in seen_ids and len(results) < limit:
                seen_ids.add(row[0])
                results.append({
                    'id': row[0],
                    'content': row[1],
                    'type': row[2],
                    'importance': row[3],
                    'created_at': row[4],
                    'tags': row[5],
                    'source': 'git_keywords'
                })
    except:
        pass

    return results


def search_recent_memories(conn: sqlite3.Connection, project: str, days: int, limit: int) -> List[Dict]:
    """ìµœê·¼ Nì¼ ì´ë‚´ ë©”ëª¨ë¦¬"""
    cursor = conn.cursor()

    cursor.execute('''
        SELECT id, content, memory_type, importance, created_at, tags
        FROM memories
        WHERE project = ?
          AND created_at > datetime('now', ?)
        ORDER BY created_at DESC, importance DESC
        LIMIT ?
    ''', (project, f'-{days} days', limit))

    return [{
        'id': row[0],
        'content': row[1],
        'type': row[2],
        'importance': row[3],
        'created_at': row[4],
        'tags': row[5],
        'source': 'recent'
    } for row in cursor.fetchall()]


def search_important_memories(conn: sqlite3.Connection, project: str, limit: int) -> List[Dict]:
    """ì¤‘ìš” ë©”ëª¨ë¦¬ (decision, error, architecture ë“±)"""
    cursor = conn.cursor()

    # ì¤‘ìš” íƒ€ì… + ë†’ì€ ì¤‘ìš”ë„
    cursor.execute('''
        SELECT id, content, memory_type, importance, created_at, tags
        FROM memories
        WHERE project = ?
          AND (memory_type IN ('decision', 'error') OR importance >= 8)
        ORDER BY importance DESC, created_at DESC
        LIMIT ?
    ''', (project, limit))

    return [{
        'id': row[0],
        'content': row[1],
        'type': row[2],
        'importance': row[3],
        'created_at': row[4],
        'tags': row[5],
        'source': 'important'
    } for row in cursor.fetchall()]


def search_fallback_memories(conn: sqlite3.Connection, project: str, limit: int) -> List[Dict]:
    """í´ë°±: ì¼ë°˜ ë©”ëª¨ë¦¬"""
    cursor = conn.cursor()

    cursor.execute('''
        SELECT id, content, memory_type, importance, created_at, tags
        FROM memories
        WHERE project = ?
        ORDER BY importance DESC, accessed_at DESC
        LIMIT ?
    ''', (project, limit))

    return [{
        'id': row[0],
        'content': row[1],
        'type': row[2],
        'importance': row[3],
        'created_at': row[4],
        'tags': row[5],
        'source': 'fallback'
    } for row in cursor.fetchall()]


def deduplicate_memories(memories: List[Dict]) -> List[Dict]:
    """ì¤‘ë³µ ì œê±° (ID ê¸°ì¤€)"""
    seen = set()
    unique = []
    for m in memories:
        if m['id'] not in seen:
            seen.add(m['id'])
            unique.append(m)
    return unique


def load_project_context(conn: sqlite3.Connection, project: str) -> Dict[str, Any]:
    """í”„ë¡œì íŠ¸ ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ"""
    cursor = conn.cursor()
    context = {}

    # ê¸°ìˆ  ìŠ¤íƒ
    cursor.execute('SELECT tech_stack FROM project_context WHERE project = ?', (project,))
    row = cursor.fetchone()
    if row and row[0]:
        context['tech_stack'] = json.loads(row[0])

    # í™œì„± ìƒíƒœ
    cursor.execute('SELECT current_state, blockers FROM active_context WHERE project = ?', (project,))
    row = cursor.fetchone()
    if row:
        context['current_state'] = row[0]
        context['blockers'] = row[1]

    # ìµœê·¼ ì„¸ì…˜
    cursor.execute('SELECT last_work, next_tasks FROM sessions WHERE project = ? ORDER BY timestamp DESC LIMIT 1', (project,))
    row = cursor.fetchone()
    if row:
        context['last_work'] = row[0]
        context['next_steps'] = json.loads(row[1]) if row[1] else []

    # ë¯¸ì™„ë£Œ íƒœìŠ¤í¬
    cursor.execute('''
        SELECT title, priority FROM tasks
        WHERE project = ? AND status IN ('pending', 'in_progress')
        ORDER BY priority DESC LIMIT 5
    ''', (project,))
    context['pending_tasks'] = [{'title': r[0], 'priority': r[1]} for r in cursor.fetchall()]

    return context


def format_memory(m: Dict) -> str:
    """ë©”ëª¨ë¦¬ í¬ë§·íŒ…"""
    content = m['content']
    # í•´ì‹œ íƒœê·¸ ì œê±°
    if content.startswith('[') and ']' in content:
        content = content.split(']', 1)[1].strip()

    # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
    if len(content) > 150:
        content = content[:147] + '...'

    type_icons = {
        'decision': 'ğŸ¯',
        'error': 'âš ï¸',
        'learning': 'ğŸ“š',
        'implementation': 'ğŸ”§',
        'important': 'â—',
        'code': 'ğŸ’»',
        'observation': 'ğŸ‘€'
    }
    icon = type_icons.get(m['type'], 'ğŸ’­')

    # ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ê²½ìš° ìœ ì‚¬ë„ í‘œì‹œ
    similarity_str = ''
    if m.get('source') == 'semantic' and m.get('similarity'):
        similarity_str = f" (sim: {m['similarity']:.2f})"

    return f"- {icon} [{m['type']}] {content}{similarity_str}"


def format_output(project: str, context: Dict, memories: List[Dict]) -> str:
    """ìµœì¢… ì¶œë ¥ í¬ë§·"""
    lines = [f"# ğŸš€ {project} - Session Resumed\n"]

    # ê¸°ìˆ  ìŠ¤íƒ
    if context.get('tech_stack'):
        stack = context['tech_stack']
        stack_str = ', '.join(f"**{k}**: {v}" for k, v in stack.items() if v)
        if stack_str:
            lines.append(f"## Tech Stack")
            lines.append(stack_str)
            lines.append('')

    # í˜„ì¬ ìƒíƒœ
    if context.get('current_state'):
        lines.append(f"## Current State")
        lines.append(f"ğŸ“ {context['current_state']}")
        if context.get('blockers'):
            lines.append(f"ğŸš§ **Blocker**: {context['blockers']}")
        lines.append('')

    # ë§ˆì§€ë§‰ ì‘ì—…
    if context.get('last_work'):
        lines.append(f"## Last Work")
        lines.append(context['last_work'][:200])
        if context.get('next_steps'):
            lines.append(f"**Next**: {' â†’ '.join(context['next_steps'][:3])}")
        lines.append('')

    # ë¯¸ì™„ë£Œ íƒœìŠ¤í¬
    if context.get('pending_tasks'):
        lines.append(f"## ğŸ“‹ Pending Tasks")
        for t in context['pending_tasks'][:5]:
            lines.append(f"- [P{t['priority']}] {t['title']}")
        lines.append('')

    # ê´€ë ¨ ë©”ëª¨ë¦¬ (í•µì‹¬!)
    if memories:
        lines.append(f"## ğŸ§  Relevant Memories ({len(memories)})")
        for m in memories[:8]:  # ìµœëŒ€ 8ê°œ
            lines.append(format_memory(m))
        lines.append('')

    lines.append("---")
    lines.append("_Auto-loaded by MCP v6 (Semantic Search). Use `#remember` to save important info._")

    return '\n'.join(lines)


def main():
    try:
        input_data = json.load(sys.stdin)
        cwd = input_data.get("cwd", os.getcwd())

        project = get_project_from_cwd(cwd)
        if not project:
            sys.exit(0)

        if not os.path.exists(DB_PATH):
            print(f"\n[Session] Project: {project} (no database - run project_init)\n")
            sys.exit(0)

        # í”„ë¡œì íŠ¸ ê²½ë¡œ
        if 'tools/' in cwd:
            project_path = os.path.join(WORKSPACE_ROOT, 'tools', project)
        else:
            project_path = os.path.join(APPS_DIR, project)

        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row

        # Git í‚¤ì›Œë“œ ì¶”ì¶œ (ì—¬ëŸ¬ Phaseì—ì„œ ì‚¬ìš©)
        git_keywords = extract_git_keywords(project_path) if os.path.exists(project_path) else []

        # Phase 0: ì‹œë§¨í‹± ê²€ìƒ‰ (ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜)
        semantic_memories = search_semantic_memories(conn, project, git_keywords, SLOT_CONFIG['semantic'])

        # Phase 1: Git í‚¤ì›Œë“œ ê¸°ë°˜ FTS ê²€ìƒ‰
        git_memories = search_memories_by_keywords(conn, project, git_keywords, SLOT_CONFIG['git_related'])

        # Phase 2: ìµœê·¼ 7ì¼ ë©”ëª¨ë¦¬
        recent_memories = search_recent_memories(conn, project, 7, SLOT_CONFIG['recent'])

        # Phase 3: ì¤‘ìš” ë©”ëª¨ë¦¬
        important_memories = search_important_memories(conn, project, SLOT_CONFIG['important'])

        # Phase 4: í´ë°±
        fallback_memories = search_fallback_memories(conn, project, SLOT_CONFIG['fallback'])

        # ë³‘í•© + ì¤‘ë³µ ì œê±° (ì‹œë§¨í‹± ê²€ìƒ‰ ê²°ê³¼ ìš°ì„ )
        all_memories = deduplicate_memories(
            semantic_memories + git_memories + recent_memories + important_memories + fallback_memories
        )[:12]  # ìµœëŒ€ 12ê°œ

        # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸
        context = load_project_context(conn, project)

        conn.close()

        # ì¶œë ¥
        if context or all_memories:
            output = format_output(project, context, all_memories)
            print(f"\n<session-context project=\"{project}\">\n{output}\n</session-context>\n")
        else:
            print(f"\n[Session] Project: {project} (no context yet - use project_init)\n")

        sys.exit(0)

    except Exception as e:
        print(f"<!-- Hook error: {e} -->", file=sys.stderr)
        sys.exit(0)


if __name__ == "__main__":
    main()
